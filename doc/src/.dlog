*** error: more than one subsection in a slide (insert missing !split):
% !split
\subsection{CNN Interpretability}
 \begin{itemize}
\begin{enumerate}
  \item CNNs are often seen as "black boxes", but their learned filters can sometimes be interpreted.

  \item Outputs correlate with known physics: \begin{itemize}
\begin{enumerate}

      \item At low $T$: classification heavily influenced by magnetization (order).

      \item At high $T$: classification influenced by internal energy (disorder) 
\end{enumerate}

\noindent
     \end{itemize}

  \item CNNs can generalize: e.g.\ Ising-trained CNN finds Potts $T_c$ 

  \item Visualization methods (e.g.\ saliency maps) can highlight what CNN focuses on.
\end{enumerate}

\noindent
 \end{itemize}
\end{frame}

\subsection{[fragile]{CNN (PyTorch) Code Example}


























\begin{minted}[fontsize=\fontsize{9pt}{9pt},linenos=false,mathescape,baselinestretch=1.0,fontfamily=tt,xleftmargin=2mm]{python}
import torch
import torch.nn as nn
import torch.nn.functional as F

class PhaseCNN(nn.Module):
   def __init__(self, L):
       super(PhaseCNN, self).__init__()
       self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)  # 1 channel -> 8
       self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1) # 8 -> 16
       self.pool = nn.MaxPool2d(2)  # downsample by 2
       self.fc1 = nn.Linear(16 * (L//2) * (L//2), 64)
       self.fc2 = nn.Linear(64, 2)  # 2 output classes

   def forward(self, x):
       x = F.relu(self.conv1(x))      # (B,8,L,L)
       x = self.pool(F.relu(self.conv2(x)))  # (B,16,L/2,L/2)
       x = x.view(x.size(0), -1)      # flatten
       x = F.relu(self.fc1(x))
       x = self.fc2(x)               # logits for 2 classes
       return x

# Example usage:
model = PhaseCNN(L=32)           # for a 32x32 lattice
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

\end{minted}



